# AI Chatbot cho 10,000 NhÃ¢n ViÃªn - ME

Chatbot há»— trá»£ nhÃ¢n viÃªn vá»›i kháº£ nÄƒng:

- ğŸ” TÃ¬m kiáº¿m tÃ i liá»‡u báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn
- ğŸ“Š So sÃ¡nh cÃ¡c phiÃªn báº£n tÃ i liá»‡u khÃ¡c nhau
- ğŸ¤– Sá»­ dá»¥ng LLM local **MIá»„N PHÃ** qua Ollama
- ğŸ‡»ğŸ‡³ Há»— trá»£ tiáº¿ng Viá»‡t xuáº¥t sáº¯c vá»›i Qwen2

## CÃ´ng nghá»‡ sá»­ dá»¥ng

- **LLM**: Qwen2 (4.4GB) - Há»— trá»£ tiáº¿ng Viá»‡t tá»‘t nháº¥t
- **LLM Runtime**: Ollama (miá»…n phÃ­, cháº¡y local, khÃ´ng cáº§n API key)
- **Framework**: Langchain
- **Language**: Python
- **UI**: Gradio & Node.js Web Interface
- **Vector DB**: FAISS
- **Embeddings**: Sentence Transformers (multilingual)

## CÃ i Ä‘áº·t

### 1. Python Backend

```bash
# Táº¡o virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
# hoáº·c: venv\Scripts\activate  # Windows

# CÃ i Ä‘áº·t dependencies
pip install -r requirements.txt
```

### 2. CÃ i Ä‘áº·t Ollama (LLM miá»…n phÃ­)

**macOS:**

```bash
# Táº£i vÃ  cÃ i Ä‘áº·t tá»« website
open https://ollama.com/download

# HOáº¶C dÃ¹ng Homebrew
brew install ollama
```

**Linux:**

```bash
curl -fsSL https://ollama.com/install.sh | sh
```

**Windows:**
Táº£i installer tá»«: https://ollama.com/download

**Khá»Ÿi Ä‘á»™ng Ollama:**

```bash
# Start Ollama service (cháº¡y trong terminal riÃªng)
ollama serve

# Download model Qwen2 (4.4GB - tá»‘t nháº¥t cho tiáº¿ng Viá»‡t)
ollama pull qwen2
```

### 3. Cáº¥u hÃ¬nh

```bash
# Copy file cáº¥u hÃ¬nh
cp .env.example .env

# File .env Ä‘Ã£ Ä‘Æ°á»£c cáº¥u hÃ¬nh sáºµn cho Ollama + Qwen2
# KhÃ´ng cáº§n chá»‰nh sá»­a gÃ¬ thÃªm!
```

### 4. ThÃªm tÃ i liá»‡u

```bash
# Táº¡o thÆ° má»¥c documents
mkdir -p documents

# Copy cÃ¡c file PDF, DOCX vÃ o thÆ° má»¥c documents/
# Há»‡ thá»‘ng sáº½ tá»± Ä‘á»™ng xá»­ lÃ½ vÃ  index
```

## Cháº¡y á»©ng dá»¥ng

**LÆ°u Ã½:** Äáº£m báº£o Ollama Ä‘ang cháº¡y trÆ°á»›c khi start chatbot!

### Option 1: Gradio Interface (KhuyÃªn dÃ¹ng)

```bash
python app_gradio.py
```

Má»Ÿ browser táº¡i: `http://localhost:7860`

### Option 2: Node.js Web Interface

**Terminal 1 - Python API Server:**

```bash
python api_server.py
```

**Terminal 2 - Node.js Web Server:**

```bash
cd web
npm install  # Chá»‰ cáº§n cháº¡y láº§n Ä‘áº§u
npm start
```

Má»Ÿ browser táº¡i: `http://localhost:3000`

## Cáº¥u trÃºc thÆ° má»¥c

```
internal-chatbot/
â”œâ”€â”€ documents/              # ThÆ° má»¥c chá»©a tÃ i liá»‡u
â”œâ”€â”€ vector_db/             # Vector database
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ chatbot.py         # Core chatbot logic
â”‚   â”œâ”€â”€ document_processor.py  # Xá»­ lÃ½ tÃ i liá»‡u
â”‚   â”œâ”€â”€ vector_store.py    # Vector store management
â”‚   â””â”€â”€ document_compare.py    # So sÃ¡nh tÃ i liá»‡u
â”œâ”€â”€ app_gradio.py          # Gradio interface
â”œâ”€â”€ api_server.py          # Flask API server
â”œâ”€â”€ web/                   # Node.js web interface
â”‚   â”œâ”€â”€ server.js
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ public/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## TÃ­nh nÄƒng

### 1. TÃ¬m kiáº¿m tÃ i liá»‡u

- Há»i báº±ng ngÃ´n ngá»¯ tá»± nhiÃªn (tiáº¿ng Viá»‡t hoáº·c tiáº¿ng Anh)
- TÃ¬m kiáº¿m semantic search vá»›i FAISS
- Tráº£ vá» nguá»“n tÃ i liá»‡u tham kháº£o

### 2. So sÃ¡nh tÃ i liá»‡u

- So sÃ¡nh 2 phiÃªn báº£n tÃ i liá»‡u
- Highlight cÃ¡c thay Ä‘á»•i
- TÃ³m táº¯t sá»± khÃ¡c biá»‡t

### 3. HoÃ n toÃ n miá»…n phÃ­

- âœ… KhÃ´ng cáº§n API key
- âœ… Cháº¡y offline trÃªn mÃ¡y cá»§a báº¡n
- âœ… KhÃ´ng lo vá» quota hay chi phÃ­
- âœ… Dá»¯ liá»‡u Ä‘Æ°á»£c báº£o máº­t hoÃ n toÃ n

## API Endpoints

```
POST /api/chat
- Body: {"message": "cÃ¢u há»i", "conversation_id": "optional"}
- Response: {"answer": "...", "sources": [...]}

POST /api/compare
- Body: {"doc1": "path1", "doc2": "path2"}
- Response: {"differences": "...", "summary": "..."}

POST /api/upload
- Body: FormData with file
- Response: {"status": "success", "filename": "..."}
```

## CÃ¡c LLM Models Ä‘Æ°á»£c há»— trá»£

Báº¡n cÃ³ thá»ƒ thay Ä‘á»•i model trong file `.env`:

| Model        | Tiáº¿ng Viá»‡t | Size  | RAM cáº§n | KhuyÃªn dÃ¹ng       |
| ------------ | ---------- | ----- | ------- | ----------------- |
| **qwen2** â­ | â­â­â­â­â­ | 4.4GB | 8GB     | âœ… Tá»‘t nháº¥t       |
| llama3       | â­â­â­â­   | 4.7GB | 8GB     | âœ… Cháº¥t lÆ°á»£ng cao |
| mistral      | â­â­â­     | 4.1GB | 8GB     | âœ… Nhanh          |
| phi3         | â­â­       | 2.2GB | 4GB     | âš ï¸ Yáº¿u tiáº¿ng Viá»‡t |

**Äá»•i model:**

```bash
# Download model khÃ¡c
ollama pull llama3

# Sá»­a file .env
OLLAMA_MODEL=llama3
```

## TÃ¹y chá»n LLM khÃ¡c

NgoÃ i Ollama (máº·c Ä‘á»‹nh), báº¡n cÃ³ thá»ƒ dÃ¹ng:

### Option A: OpenAI API (tráº£ phÃ­)

```bash
# Trong .env
LLM_PROVIDER=openai
OPENAI_API_KEY=sk-your-key-here
```

### Option B: vLLM (Advanced)

```bash
# CÃ i Ä‘áº·t vLLM
pip install vllm

# Cháº¡y vLLM server
python -m vllm.entrypoints.openai.api_server \
    --model Qwen/Qwen2-7B-Instruct

# Trong .env
LLM_PROVIDER=vllm
LLM_API_BASE=http://localhost:8000/v1
```

## Xem thÃªm

- [OLLAMA_SETUP.md](OLLAMA_SETUP.md) - HÆ°á»›ng dáº«n chi tiáº¿t vá» Ollama
- [SETUP.md](SETUP.md) - HÆ°á»›ng dáº«n setup Ä‘áº§y Ä‘á»§

## License

MIT
